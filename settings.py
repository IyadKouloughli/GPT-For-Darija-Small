# Path to the dataset file used for training
DATASET_PATH = "data/train.txt"

# Number of sequences to process in each batch during tokenizer training
BATCH_SIZE = 1000

# Total number of unique tokens in the Darija vocabulary
VOCAB_SIZE = 50000